
# 深度残差学习为图像识别

*Kaiming He, Xianyu Zhang, Shaoqing Ren, Jian Sun*

*Microsoft Research*

## 摘要

越深的神经网络越难训练。我们提出一个残差学习框架，使训练比那些先前提出的网络还要深的多的网络变得容易。我们利用------我们提供具有竞争力的经验证据显示这些残差网络是易于优化的，且可以从大大增加的深度中获得精度。在ImageNet数据集中，我们评估残差网络以一个深度达到152层——8倍于VGG网络深度，但是仍旧有更低的复杂度。一套这些残差网络获得了3.57%误差在ImageNet测试集中。这个结果赢得了第一的位置在ILSVRC 2015分类任务中。我们也提供了在CIFAR-10中100-1000层的分析。

## 1. 导言

深度卷积神经网络[22, 21]已经导致一系列的突破在图片分类中。深度网络自然地整合低/中/高级别特征和分类器，以一个端到端的多层方式，且特征的“等级”能够被丰富，通过一定数量的被堆叠的层（深度）。最近的证据[41，44]揭示了网络深度是至关重要的，且导致的结果在挑战ImageNet数据集中都利用“非常深”的模型，深度从16[41]到30[16]。很多其他的非凡的视觉识别任务[8,12,7,32,27]也从非常深的模型中获益。

受至关重要的深度驱动，一个问题冒了出来：学习更好的网络像叠更多层一样简单吗？一个障碍来回答这个问题就是臭名昭著的梯度消失/爆炸问题[1, 9]，这阻碍了从开始的收敛。这个问题，然而，被极大地缓解通过初始归一化[23, 9, 37, 13]和中间的归一化层[16]，这使得几十层的网络靠随机梯度下降和反向传播开始收敛。

当更深的网络能够开始收敛，一个退化问题被暴露出来：随着网络深度的增长，精度开始饱和（或许也不奇怪），然后快速降低。未预料到的是，这个退化不是由过拟合引起的，且增加更多的层到一个适当深度的模型会导致更高的训练误差，如[11, 42]中的报告，且通过我们的实验彻底验证了。图1，展示了一个典型的例子。

![](img\resnet_fig1_train_error.png "")

图1. 训练误差（左）和测试误差（右边）在CIFAR-10中，用20层和56层“白板”网络。更深的网络有更高的训练误差，和这样的测试误差。相似的现象在ImageNet中被呈现在图4中。

（训练精度的）退化表明不是所有的系统都是同样易于优化的。让我们考虑一个浅的架构，和它增加更多层的更深版本。存在一个解决通过构造更深的模型：增加的层是恒等映射，其它层是从被学习的浅模型中拷贝而来。这个构造的方案的存在证明了一个更深的模型不应该产生比相应浅模型更高的训练误差。但是经验展示我们当前手上的解决者无法找到比被构造的解决一样好或更好的解决（或者不能在可行的时间中办到）。

在这个论文中，我们通过引入一个深度残差学习框架来缓解问题。抛弃寄希望于每个少量堆叠的层直接拟合一个残余映射。正式地，记想要的底层映射为$\mathcal H(x)$，我们让堆叠的非线性层拟合另一个映射$\mathcal F(x):= \mathcal H(x) - x$。原始的映射被重写为$\mathcal F(x)+x$。我们假设优化残差映射相较于优化原始的无引用映射更容易。走向极端，如果一个恒等映射优化好了，相较于通过一个非线性层的堆叠拟合一个恒等映射，将残差逼成0更容易。

公式$F(x)+x$

## 2. 相关工作



## 3. 深度残差学习



## 4. 实验


